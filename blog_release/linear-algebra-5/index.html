<!DOCTYPE html>
<html>
  <head>
    <title>线性代数之正交矩阵与QR分解 – Wyman的原创技术博客 – 恭喜你发现我的小站，撩我请加QQ：234707482、Wechat：_Wyman</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>
    <meta name="baidu-site-verification" content="0OpfO1OtHA" />
    
    <meta name="description" content="基础知识

标准正交向量组（Orthonormal vectors）的点积(内积)性质：

\( q_{i}^{T}q_{j} = 0 \) if \( i\neq j \)

\( q_{i}^{T}q_{j} = 1 \) if \( i = j \)

其中每个正交向量的长度\(||q_{i}||=1\)。

标准正交向量组成的矩阵是：
" />
    <meta property="og:description" content="基础知识

标准正交向量组（Orthonormal vectors）的点积(内积)性质：

\( q_{i}^{T}q_{j} = 0 \) if \( i\neq j \)

\( q_{i}^{T}q_{j} = 1 \) if \( i = j \)

其中每个正交向量的长度\(||q_{i}||=1\)。

标准正交向量组成的矩阵是：
" />
    
    <meta name="author" content="Wyman的原创技术博客" />

    
    <meta property="og:title" content="线性代数之正交矩阵与QR分解" />
    <meta property="twitter:title" content="线性代数之正交矩阵与QR分解" />
    

    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Wyman的原创技术博客 - 恭喜你发现我的小站，撩我请加QQ：234707482、Wechat：_Wyman" href="/feed.xml" />
    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-65954265-1', 'auto');
		ga('send', 'pageview', {
		  'page': '/linear-algebra-5/',
		  'title': '线性代数之正交矩阵与QR分解'
		});
	</script>
	<!-- End Google Analytics -->
	<!-- Baidu Analytics -->
	<script>
		var _hmt = _hmt || [];
		(function() {
		  var hm = document.createElement("script");
		  hm.src = "//hm.baidu.com/hm.js?0dc968591d8c64196a37eca9ca4f86b3";
		  var s = document.getElementsByTagName("script")[0]; 
		  s.parentNode.insertBefore(hm, s);
		})();
	</script>
	<!-- End Baidu Analytics -->

  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="https://www.qiujiawei.com/images/avatar.jpg" /></a>

          <div class="site-info">
            <h1 class="site-name"><a href="/">Wyman的原创技术博客</a></h1>
            <p class="site-description">恭喜你发现我的小站，撩我请加QQ：234707482、Wechat：_Wyman</p>
          </div>

          <nav>
            <a href="/">Blog</a>
            <a href="/about">About</a>
          </nav>
        </header>
      </div>
    </div>

    <nav class="nav2">
      <ul></ul>
    </nav>

    <div id="main" role="main" class="container">
      <section>  
        <script src="https://code.jquery.com/jquery-3.3.0.min.js" integrity="sha256-RTQy8VOmNlT6b2PIRur37p6JEBZUE7o8wPgMvu18MC4=" crossorigin="anonymous"></script>
<script src="/main.js"></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
<h1>线性代数之正交矩阵与QR分解</h1>
 <h3>Tags: <a href="/tag/matrix/" rel="tag">matrix</a>, <a href="/tag/linear-algebra/" rel="tag">linear algebra</a></h3>
<article class="post">
    
    <div class="entry">
        <h2>基础知识</h2>

<p>标准正交向量组（Orthonormal vectors）的点积(内积)性质：</p>

<p>\( q_{i}^{T}q_{j} = 0 \) <strong>if</strong> \( i\neq j \)</p>

<p>\( q_{i}^{T}q_{j} = 1 \) <strong>if</strong> \( i = j \)</p>

<p>其中每个正交向量的长度\(||q_{i}||=1\)。</p>

<p>标准正交向量组成的矩阵是：</p>

<!--more-->

<p>\( Q = \) \(  \left[ \begin{matrix} q_{1}&amp;\cdots&amp;q_{n}\\ \end{matrix} \right] \)</p>

<p>注意，列向量的分量数量未知，Q所以不一定是方阵。</p>

<p>\( Q^{T}Q =  \left[ \begin{matrix} q_{1}^{T}\\ \vdots\\ q_{n}^{T}\\ \end{matrix} \right] \left[ \begin{matrix} q_{1}&amp;\cdots&amp;q_{n}\\ \end{matrix} \right] = I \)</p>

<p>当Q是方阵时，显然Q有逆矩阵，且\( Q^{-1} = Q^{T} \)。</p>

<p>比如当Q为3阶单位矩阵I的置换矩阵时：</p>

<p>\( Q^{T}Q =  \left[ \begin{matrix} 0&amp;1&amp;0\\ 0&amp;0&amp;1\\ 1&amp;0&amp;0\\ \end{matrix} \right] \left[ \begin{matrix} 0&amp;0&amp;1\\ 1&amp;0&amp;0\\ 0&amp;1&amp;0\\ \end{matrix} \right] = I \)</p>

<p>或者三角函数作为元素的二阶Q：</p>

<p>\( Q^{T}Q =  \left[ \begin{matrix} cos\theta&amp;-sin\theta\\ sin\theta&amp;cos\theta\\ \end{matrix} \right]  \left[ \begin{matrix} cos\theta&amp;sin\theta\\ -sin\theta&amp;cos\theta\\ \end{matrix} \right] = I \)</p>

<h2>定义</h2>

<ul>
<li><p>如果实数域上的方阵A满足 \( A^{T}A = I \)，则称A为正交矩阵</p></li>
<li><p>当A的列向量的长度都为1时，称A为标准正交矩阵Q。</p></li>
</ul>

<h2>定理</h2>

<ul>
<li>当\(A^{-1} = A^{T}\)成立时A是正交矩阵</li>
<li>A的列(或行)向量组是\(R^{n}\)的一组标准正交基时，A是正交矩阵</li>
<li>正交矩阵A的行列式为1或-1</li>
<li>如果A是正交矩阵，则\(A^{-1},A^{T},A^{*}\)都是正交矩阵</li>
<li>如果A、B都是正交矩阵，那么AB也是正交矩阵</li>
</ul>

<h2>正交矩阵怎么用？</h2>

<p>在上一篇文章中，讲到了投影矩阵的各种公式，其中有一条是：</p>

<p>\[ A^{T}A\hat{x} = A^{T}b \]</p>

<p>这个戴着帽子的x是未知量，要求它的值，就需要再变换下：</p>

<p>\[ \hat{x} = (A^{T}A)^{-1}A^{T}b \]</p>

<p>那么问题来了：右边的式子有点复杂，又要算矩阵乘法又要算逆矩阵，是不是可以简化呢？</p>

<p>答案是可以，且要用到正交矩阵。因为A是由一组线性无关的列向量组成，当把这组向量转换为标准正交向量组时，就得到了标准正交矩阵Q。拿Q代入上面的式子，得到：</p>

<p>\[ Q^{T}Q\hat{x} = Q^{T}b \]</p>

<p>再根据上述的Q的公式，干掉左边的2个Q，得到：</p>

<p>\[ \hat{x} = Q^{T}b \]</p>

<p>瞬间豁然开朗。</p>

<p>但是还有一个问题，怎么从A得到Q呢？</p>

<h2>矩阵的正交化算法</h2>

<p>因为从A可以得到Q，所以必然有某个矩阵R，使得 A = QR 成立，这个过程叫做A的QR分解（QR decomposition)。</p>

<h3>先举一个二维的例子：</h3>

<p>设 \(\mathbf a1 = (3,4)、\mathbf a2 = (4,3)\)，显然\(\mathbf a1、\mathbf a2\)线性无关（不在同一条直线上），且\(\mathbf a1、\mathbf a2\)的长度都不是1。\(\mathbf a1、\mathbf a2\)是二维空间的一组基(basis)。</p>

<p>\(\mathbf a1、\mathbf a2\)对应的矩阵为：</p>

<p>\[ A =  \left[ \begin{matrix} \mathbf a_{1}&amp; \mathbf a_{2}\\ \end{matrix} \right] =  \left[ \begin{matrix} 3&amp;4\\ 4&amp;3\\ \end{matrix} \right] \]</p>

<p>显然，A是一个方阵。接下来就是实现A的QR分解。</p>

<p>标准正交矩阵，可以分为2个步骤实现：</p>

<ol>
<li>正交化(orthogonal)</li>
<li>标准化(normalize)</li>
</ol>

<p>二维空间下，让2个向量正交化，即等于是要找出2个互相垂直的向量。怎么找最简单呢？因为这样的向量组无限多，于是\(\mathbf a1 或 \mathbf a2\)都可以是某组正交向量的其中一个向量。</p>

<p>那么，我们可以让\(\mathbf a1\)作为一个正交向量，然后再找出一个与\(\mathbf a1\)垂直的向量，就得到一组正交向量了。</p>

<p>设\(\mathbf u1、\mathbf u2\)为要求的标准正交向量组，\(\mathbf n1、\mathbf n2\)代表\(\mathbf a1、\mathbf a2\)的单位向量，那么可以有：</p>

<p>\[ \mathbf u_{1} = \mathbf n_{1} \]</p>

<p>\(\mathbf u2\)怎么求？很简单，利用投影矩阵的知识即可完成。因为\(\mathbf a2 和 \mathbf a1\)线性无关，那么\(\mathbf a2 在 \mathbf a1\)上有且只有一个投影点\(\mathbf p2\)，算出这个投影点\(\mathbf p2\)，就能快速得到\(\mathbf a2\)关于\(\mathbf a1\)的error向量：</p>

<p>\[ \mathbf e_{2} = \mathbf a_{2} - \mathbf p_{2} \]</p>

<p>为什么要算\(\mathbf e2\)向量？因为\(\mathbf e2\)向量的一个重要性质是，\(\mathbf e2\)和\(\mathbf a1\)是互相垂直的，换句话说就是，<strong>\(\mathbf e2\)和\(\mathbf a1\)正交!</strong>。有了\(\mathbf e2\)，将其单位化后，就是\(\mathbf u2\)了。</p>

<p>求\(\mathbf u2\)的步骤：</p>

<ul>
<li>先求\(\mathbf n1\)，即\(\mathbf a1\)的单位向量</li>
</ul>

<p>\[ \mathbf n_{1} = \dfrac { \mathbf a_{1} }{ ||\mathbf a_{1}|| } \] </p>

<ul>
<li>求出\(\mathbf a2\)在\(\mathbf a1\)上的投影点\(\mathbf p2\) <a href="https://en.wikipedia.org/wiki/Vector_projection">vector projection</a></li>
</ul>

<p>\[ \mathbf p_{2} = \mathbf n_{1}\dfrac { \mathbf n_{1}\cdot \mathbf a_{2} }{  \mathbf n_{1}\cdot \mathbf n_{1} } = \mathbf n_{1}(\mathbf n_{1}\cdot \mathbf a_{2}) \] </p>

<p>那个分母为什么可以去掉呢？这是因为\(\mathbf n1\)是单位向量，\( \mathbf n_{1}\cdot \mathbf n_{1} \)是\(\mathbf n1\)的内积，显然这个内积等于1。</p>

<ul>
<li>求\(\mathbf e2\)</li>
</ul>

<p>\[ \mathbf e_{2} = \mathbf a_{2} - \mathbf p_{2} = \mathbf a_{2} - \mathbf n_{1}(\mathbf n_{1}\cdot \mathbf a_{2}) \]</p>

<ul>
<li>单位化\(\mathbf e2\)，得到\(\mathbf u2\)</li>
</ul>

<p>\[ \mathbf u_{2} = \dfrac { \mathbf e_{2} }{ ||\mathbf e_{2}|| } \]</p>

<p>好了，公式出来了，拿上面的例子验证下：</p>

<p>\[ \mathbf u_{1} = \mathbf n_{1} = \dfrac { \mathbf a_{1} }{ ||\mathbf a_{1}|| } = (\dfrac {3}{5},\dfrac {4}{5} ) \]</p>

<p>\[ \mathbf e_{2} = \mathbf a_{2} - \mathbf p_{2} = \mathbf a_{2} - \mathbf n_{1}(\mathbf n_{1}\cdot \mathbf a_{2}) = (\dfrac {28}{25},\dfrac {-21}{25}) \]</p>

<p>\[ \mathbf u_{2} = \dfrac { \mathbf e_{2} }{ ||\mathbf e_{2}|| } = (\dfrac {4}{5},\dfrac {-3}{5}) \]</p>

<p>\[ \mathbf u_{1} \cdot \mathbf u_{2} = (\dfrac {3}{5},\dfrac {4}{5}) \cdot (\dfrac {4}{5},\dfrac {-3}{5}) = 0 \]</p>

<p>u1和u2的内积为0，且长度均为1，所以U1和u2是一组标准正交向量。</p>

<p>\[ Q =  \left[ \begin{matrix} \mathbf u_{1}&amp; \mathbf u_{2}\\ \end{matrix} \right] \]</p>

<h3>高维时的通用QR解法</h3>

<p>上面是维度为2时的QR分解过程，接下来谈谈3维以及n维的情况。</p>

<p>当维度为3时，还是比较好想象的，我们分步构想下QR分解过程：</p>

<ul>
<li>A矩阵由3个线性无关的向量构成，A的列空间是一个三维空间，即三维空间的任意一个点都可以通过线性组合这3个向量得到</li>
<li>设3个向量为a1、a2、a3，先对a1、a2进行正交化运算，过程和上述的一致，除了\(\mathbf a_{i}\)变成了3个分量。</li>
<li>正交化a1、a2，就得到了a1、a2对应的平面空间的一组标准正交基u1、u2</li>
<li>于是原问题变成：求解u1、u2、a3的正交化。u1和u2已经是标准正交向量，不用管它们，问题就是求出u3。</li>
<li>a3是在u1、u2对应的平面<strong>之外</strong>的一个点，a3在这个平面上有且只有一个投影点p3，将它求出来</li>
<li>再求出\( e_{3} = a_{3} - p_{3} \)就得到了a3的error向量，该向量垂直于u1、u2平面！</li>
<li>将e3标准化后，就得到了u3</li>
</ul>

<p>n&gt;3维的情况，可以用归纳法解出。</p>

<p>高维情况下的QR分解，公式如下：</p>

<p>\[ A =  \left[ \begin{matrix} a_{1}&amp;a_{2}&amp;\cdots&amp;a_{n}\\ \end{matrix} \right] \]
\[ A =  \left[ \begin{matrix} u_{1}&amp;u_{2}&amp;\cdots&amp;u_{n}\\ \end{matrix} \right] \left[ \begin{matrix} a_{1}\cdot u_{1}&amp;a_{2}\cdot u_{1}&amp;\cdots &amp;a_{n}\cdot u_{1}\\ 0&amp;a_{2}\cdot u_{2}&amp;\cdots &amp;a_{n}\cdot u_{2}\\ \vdots &amp;\vdots &amp;\ddots &amp;\vdots\\ 0&amp;0&amp;\cdots &amp;a_{n}\cdot u_{n}\\ \end{matrix} \right] = QR \]</p>

<p>Q是标准正交矩阵，R是上三角矩阵。</p>

<p>证明过程略，不过可以简单分析下这公式的正确性。</p>

<p>Q乘以R的结果是A矩阵，那么可以得到：</p>

<p>\[ a_{1} = u_{1}(a_{1}\cdot u_{1}) \]</p>

<p>这个式子，是不是很眼熟，其实就是投影公式：</p>

<p>\[ p_{1} = a_{1} = u_{1}\dfrac { u_{1}^{T}a_{1} }{  u_{1}^{T} u_{1} } = u_{1}(u_{1}^{T}a_{1}) = u_{1}(a_{1}\cdot u_{1}) \] </p>

<p>（后面的内积有2种写法，同个意思，不用在意）</p>

<p>这个式子说明，经过QR分解后，a1的投影点还是a1，且在u1上。（但a1不一定等于u1）</p>

<p>我把a2也写出来：</p>

<p>\[ a_{2} = u_{1}(a_{2}\cdot u_{1}) + u_{2}(a_{2}\cdot u_{2}) \]</p>

<p>类似a1，a2 = a2在u1的投影 + a2在u2的投影。（注意：a2一定不在u上，因为这样a1和a2就线性有关了；a2不一定在u2上）</p>

<p>然后a3，就不用写了，显然a3 = a3在u1的投影 + a3在u2的投影 + a3在u2的投影。</p>

<p>\(a_{n}\)以此类推。所以这个公式是OK的。</p>

<p>总结一下：</p>

<p>要对A做QR分解，得从A本身出发，算出各个标准正交向量，并且这是一个迭代的过程：从a1算出u1，再通过a2和u1得到u2，接着，\(u_{n}\)都可以通过\(a_{n}\)和前面算出来的\(u_{i}\ \ (i&lt;n)\)得到。</p>

<p>如果QR分解的目的只是为了得到Q矩阵，那么R矩阵是没什么卵用的，因为R矩阵本身也包含了目标变量n，所以没办法用\(Q=AR^{-1}\)公式求Q矩阵。</p>

    </div>
    <div class="entry">
        (未经授权禁止转载)
    </div>
    <div class="date">
        Written on September 26, 2015
    </div>
    <p>博主将十分感谢对本文章的任意金额的打赏^_^</p>
    <img src="../images/dashang1.jpeg" />
    <img src="../images/dashang2.jpeg" />
    
    
<div class="comments">
	<div id="disqus_thread"></div>
	<script type="text/javascript">

	    var disqus_shortname = 'qiujiawei';

	    (function() {
	        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
	        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
	        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	    })();

	</script>
	<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

</article>



      </section>
    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          
<a href="mailto:voyagingmk@gmail.com"><i class="svg-icon email"></i></a>


<a href="http://github.com/barryclark/jekyll-now"><i class="svg-icon github"></i></a>




<a href="http://twitter.com/voyagingmk"><i class="svg-icon twitter"></i></a>


        </footer>
      </div>
    </div>

  </body>
</html>
