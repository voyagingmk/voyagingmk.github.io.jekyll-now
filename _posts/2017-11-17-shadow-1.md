---
layout: post_latex
title: 方差阴影贴图与切比雪夫不等式
tags: ['computer graphics']
published: true
---

要理解方差阴影贴图的来龙去脉，必须先深刻理解概率论中的几个概念：

- 矩(Moment)
- 数学期望(Mean)
- 方差(Variance)
- 马可夫不等式 (Markov's Inequality)
- 切比雪夫不等式 (Chebyshev's inequality)
- 切比雪夫不等式的one-tailed版本 (one-tailed version of Chebyshev's inequality)

<!--more-->

## 矩(Moment)

https://en.wikipedia.org/wiki/Moment_(mathematics)

给定关于实变量x、常数c的实值连续函数f(x)，它的n阶矩（n-th moment)的公式是：

\\[ \\mu \^\{n\} = \\int \_\{-\\infty \}\^\{ +\\infty  \} (x - c)\^\{n\} f(x) dx \\] 

## 数学期望(Mean)

当c = 0，n = 1时，上述公式变成：

\\[ \\mu = \\int \_\{-\\infty \}\^\{ +\\infty  \} x f(x) dx \\] 

这也就是数学期望(Mean)的积分公式。


## 方差(Variance)

当\\(c = \\mu\\)时，n阶矩可称为**n阶中心矩**；当\\(c = \\mu，n = 2\\)时，2阶中心矩的公式为：

\\[ \\mu \^\{2\} =  \\int \_\{-\\infty \}\^\{ +\\infty  \} (x - \\mu )\^\{ 2 \} f(x) dx \\] 

这其实就是方差(Variance)的积分公式。下面作简单推导。

方差的定义式为：

\\[ Var(X) = E[(X - \\mu)\^\{2\}] =  E[(X - E[X])\^\{2\}] = \\sigma \^\{2\}  \\]

可以推出：

\\[ Var(X) = E[X\^\{2\} - 2 X E[X] + E[X]\^\{2\} ] \\]

\\[ = E[X\^\{2\}] - 2 E[X] E[X] + E[X]\^\{2\} \\]

\\[ = E[X\^\{2\}] -  E[X]\^\{2\} \\]

而2阶中心矩公式可以推出：

\\[ \\int (x - \\mu )\^\{ 2 \} f(x) dx \\] 

\\[ = \\int x\^\{ 2 \} f(x) dx - 2\\mu \\int x f(x) dx + \\int \\mu \^\{ 2 \} f(x) dx \\] 

\\[ = \\int x\^\{ 2 \} f(x) dx - 2\\mu \\cdot \\mu + \\mu \^\{ 2 \} \\] 

\\[ = \\int x\^\{ 2 \} f(x) dx - \\mu \^\{ 2 \} \\] 

\\[ =E[X\^\{ 2 \}] - E[X] \^\{ 2 \} \\] 

## 马可夫不等式 (Markov's Inequality)

设X是非负的随机变量，且有a > 0，那么X大于等于a的概率不超过X的数学期望除以a：

\\[ P \_\{ X \\geq a \} \\leq \frac \{ E[X] \}\{ a \} \\]

（Note：这里的P是指概率）

### 证明：

证明前需要先理解一个概念：示性函数（Indicator）。对于任意事件e，当e发生时，\\( I \_\{e\}  = 1\\)， 当E没发生时，\\( I \_\{e\} = 0\\)。

那么把\\( X \\geq a \\)当作一个事件e，当e发生时，有：

\\[  I \_\{ X \\geq a \}  = 1  \\]

\\[   a I \_\{ X \\geq a \} \\leq X   \\]

两边同时变成数学期望，不等式依然成立：

\\[   E[a I \_\{ X \\geq a \}] \\leq E[X]   \\]

又因为数学期望的线性关系，有：

\\[  E[a I \_\{ X \\geq a \}] = a \\cdot E[I \_\{ X \\geq a \}]   \\]

又因为函数\\( I \_\{ X \\geq a \} \\)的取值只有2种，所以可直接得到：

\\[  a \\cdot E[I \_\{ X \\geq a \}] = a \\cdot ( 1\\cdot P \_\{ X \\geq a \} + 0\\cdot P \_\{ X \\lt a \}   ) \\]

\\[  = a \\cdot P \_\{ X \\geq a \} \\]

综上，就得到了：

\\[   a \\cdot P \_\{ X \\geq a \} \\leq E[X]   \\]

\\[ P \_\{ X \\geq a \} \\leq \frac \{ E[X] \}\{ a \} \\]

## 切比雪夫不等式 (Chebyshev's inequality)

设有随机变量X以及它的数学期望\\(\\mu \\) 、有限且不等于0的方差\\( \\sigma \^\{2\} \\)，对于任意>0的实数k，以下不等式成立：

\\[ P \_\{ | X - \\mu | \\geq k\\sigma \} \\leq \frac \{ 1 \}\{ k\^\{2\} \} \\]

（Note：这里的P是指概率）

这就是切比雪夫不等式。其中，因为概率P永远小于等于1，所以k值要大于1这个不等式才有意义。

### 证明：

设有随机变量\\( Y = (X - \\mu )\^\{2\} \\) 以及 \\( a = (k\\sigma )\^\{2\} \\)，代入马可夫不等式后：

\\[ P \_\{ Y \\geq a \} \\leq \frac \{ E[Y] \}\{ a \} \\]


\\[ P \_\{ (X - \\mu )\^\{2\} \\geq (k\\sigma )\^\{2\} \} \\leq \frac \{ E[(X - \\mu )\^\{2\}] \}\{ (k\\sigma )\^\{2\} \} \\]

回顾下方差公式：

\\[ Var(X) = E[(X - \\mu)\^\{2\}] = \\sigma \^\{2\} \\]

显然有：

\\[ P \_\{ (X - \\mu )\^\{2\} \\geq (k\\sigma )\^\{2\} \} \\leq \frac \{ E[(X - \\mu )\^\{2\}] \}\{ (k\\sigma )\^\{2\} \} = \frac \{ \\sigma \^\{2\} \}\{ (k\\sigma )\^\{2\} \} = \frac \{ 1 \}\{ k\^\{2\} \} \\]


左边的式子可以进一步简化：

\\[ (X - \\mu )\^\{2\} \\geq (k\\sigma )\^\{2\}  \\]


\\[ |X - \\mu | \\geq k\\sigma  \\]

（右边没有绝对值是因为有前提条件k>0，即使标准差\\(\\sigma < 0 \\)该等式依然成立 )

于是切比雪夫不等式成立：

\\[ P \_\{ | X - \\mu | \\geq k\\sigma \} \\leq \frac \{ 1 \}\{ k\^\{2\} \} \\]

## 切比雪夫不等式的one-tailed版本

切比雪夫不等式的one-tailed版本其实就是**坎泰利不等式**[Cantelli's inequality](https://en.wikipedia.org/wiki/Cantelli%27s_inequality)。坎泰利不等式公式如下：

![1.png](../images/2017.11/1.png)

(from wiki，Pr等价于上文的P）

而切比雪夫不等式的one-tailed版本如下：

\\[ P \_\{  X - \\mu  \\geq t \} \\leq \frac \{ \\sigma \^\{2\} \}\{ \\sigma \^\{2\} + t \^\{2\} \} ，t  > 0 \\] 

一模一样的。

### 证明：

要证明one-tailed公式，要用到马可夫不等式。首先定义\\(Y = X - \\mu \\)，那么就有\\(E[Y] = E[X - \\mu ] = E[X]- E[\\mu ] = \\mu - \\mu = 0\\)，以及：\\( Var[Y] = Var[X - \\mu ] = Var[X] - Var[\\mu ] = Var[X]  - 0 = Var[X] \\)。

于是：

\\[ P \_\{  Y \\geq t \} = P \_\{  Y + \\mu \\geq t + \\mu \} \leq P \_\{  (Y + \\mu)\^\{2\} \\geq (t + \\mu)\^\{2\}  \}  \\]

这时候用上马可夫不等式 \\( P \_\{ X \\geq a \} \\leq \frac \{ E[X] \}\{ a \} \\)，得到：


\\[ P \_\{  (Y + \\mu)\^\{2\} \\geq (t + \\mu)\^\{2\}  \} \\leq \frac \{ E[(Y + \\mu)\^\{2\}] \}\{ (t + \\mu)\^\{2\} \} \\]

再用上方差公式：

\\[ E[(Y + \\mu)\^\{2\}] = Var[Y + \\mu] + E[Y + \\mu]\^\{2\}   \\]

\\[ = Var[Y] + Var[\\mu] + E[Y + \\mu]\^\{2\}   \\]

\\[ = \\sigma \^\{2\} + 0 + (E[Y] + E[\\mu])\^\{2\}   \\]

\\[ = \\sigma \^\{2\} + (0 + E[\\mu])\^\{2\}   \\]

\\[ = \\sigma \^\{2\} + \\mu \^\{2\}   \\]

所以有：

\\[  P \_\{  Y \\geq t \} \leq \frac \{ \\sigma \^\{2\} + \\mu \^\{2\} \}\{ (t + \\mu)\^\{2\} \} \\]

接着令 \\( \\phi(\\mu ) = \frac \{ \\sigma \^\{2\} + \\mu \^\{2\} \}\{ (t + \\mu)\^\{2\} \} \\)，求导\\( \\phi '(\\mu ) = 0\\)时的\\( \\mu \\)值。这个导数算起来比较复杂，我找了个在线导数计算工具来辅助下（这不是广告）。

先进入[http://zh.numberempire.com/equationsolver.php](http://zh.numberempire.com/equationsolver.php)，输入： (a\^2+x\^2)/((b+x)\^2)，得到导数公式： (2*b*x-2*a\^2)/(x\^3+3*b*x\^2+3*b\^2*x+b\^3)。

a就是\\( \\sigma \\)，b就是t，x就是\\(\\mu \\)，把这个式子弄成latex：

\\[ \\phi '(\\mu ) = \frac \{ 2bx - 2a\^\{2\} \}\{ x\^\{3\} + 3bx\^\{2\} + 3b\^\{2\}x + b\^\{3\} \} = 0 \\]

这个方程也是复杂，继续用工具来算就好了。

进入[http://zh.numberempire.com/equationsolver.php](http://zh.numberempire.com/equationsolver.php)，

输入：(2*b*x-2*a\^2)/(x\^3+3*b*x\^2+3*b\^2*x+b\^3) = 0，

得到：\\( x = \\frac \{ a\^\{2\} \} \{ b \} \\) ，即：

\\[ \\mu = \\frac \{ \\sigma \^\{2\} \} \{ t \}  \\]


也就是说当\\( \\mu = \\frac \{ \\sigma \^\{2\} \} \{ t \}  \\)时，\\(  \\phi(\\mu ) \\)取得最小值。而又因为对任意的\\( \\mu \\)，概率\\( P \_\{  Y \\geq t \} \\) 都不超过\\(  \\phi(\\mu ) \\)，所以原先的不等式可以进一步简化成：


\\[  P \_\{  Y \\geq t \} \leq \frac \{ \\sigma \^\{2\} + \\mu\_\{ \* \} \^\{2\} \}\{ (t + \\mu \_\{ \* \} )\^\{2\} \}  = \frac \{ \\sigma \^\{2\} + (\\frac \{ \\sigma \^\{2\} \} \{ t \}) \^\{2\} \}\{ (t + \\frac \{ \\sigma \^\{2\} \} \{ t \} )\^\{2\} \} \\]

右边的式子继续简化；

\\[ \frac \{ \\sigma \^\{2\} + (\\frac \{ \\sigma \^\{2\} \} \{ t \}) \^\{2\} \}\{ (t + \\frac \{ \\sigma \^\{2\} \} \{ t \} )\^\{2\} \}  = \\frac \{  \frac \{ \\sigma \^\{2\}t\^\{2\} +\\sigma \^\{4\} \} \{ t\^\{2\} \}         \} \{  \frac \{ (t\^\{2\} + \\sigma \^\{2\})\^\{2\}  \} \{ t\^\{2\} \}     \}  = \frac \{ \\sigma \^\{2\}t\^\{2\} +\\sigma \^\{4\} \} \{ (t\^\{2\} + \\sigma \^\{2\})\^\{2\} \} =   \frac \{ \\sigma \^\{2\} \} \{ t\^\{2\} + \\sigma \^\{2\} \} \\]

所以：

\\[  P \_\{  Y \\geq t \} =  P \_\{  X - \\mu \\geq t \} \leq  \frac \{ \\sigma \^\{2\} \} \{ t\^\{2\} + \\sigma \^\{2\} \} \\]